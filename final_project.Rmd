---
title: "Bayesian Data Analysis of New York City's Uber Ride Data"
author: "David Arthur, Krishnan Raman"
date: "12/10/2020"
output: pdf_document
---

```{r}
library(igraph)
library(doParallel)
library(progress)
library(coda)
library(knitr)
library(kableExtra)
library(mvtnorm)
library(lattice)
library(rstan)
```

```{r}
exp.kernel <- function(x, tau21, l21){
  D <- as.matrix(dist(x, diag = TRUE, upper = TRUE))
  tau21*exp(-1/(2*l21)*D^2)
}

period.kernel <- function(x, tau22, l22){
  D <- as.matrix(dist(x, diag = TRUE))
  tau22*exp(-2/(l22)*sin(pi*D/7)^2)  
}

kernel <- function(x, tau21, tau22, l21, l22){
  exp.kernel(x, tau21, l21) + period.kernel(x, tau22, l22)
}

gp.temp <- function(x, Y, niter, parm_inits, prior_parms, 
                    mh_parms, length_scales){
  pb <- progress_bar$new(total = niter-1)
  
  sdY <- sd(Y)
  meanY <- mean(Y)
  Y2 <- scale(Y)
  x2 <- x-mean(x)
  X <- cbind(1, x2, x2^2)
  P <- ncol(X)
  N <- nrow(X)
  
  beta_save <- matrix(0, niter, P)
  sig2_save <- rep(0, niter)
  tau21_save <- rep(0, niter)
  tau22_save <- rep(0, niter)
  
  In <- diag(N)
  delta <- 10e-06
  
  beta_save[1,] <- parm_inits[["beta"]]
  sig2_save[1] <- parm_inits[["sig2"]]
  tau21_save[1] <- parm_inits[["tau21"]]
  tau22_save[1] <- parm_inits[["tau22"]]
  
  sig2a <- prior_parms[["sig2a"]]
  sig2b <- prior_parms[["sig2b"]]
  tau21a <- prior_parms[["tau21a"]]
  tau21b <- prior_parms[["tau21b"]]
  tau22a <- prior_parms[["tau22a"]]
  tau22b <- prior_parms[["tau22b"]]
  
  tau21_sd <- mh_parms[["tau21_sd"]]
  tau22_sd <- mh_parms[["tau22_sd"]]
  
  l21 <- length_scales[["l21"]]
  l22 <- length_scales[["l22"]]
  
  for (i in 2:niter){
    K <- kernel(x2, tau21_save[i-1], tau22_save[i-1], l21, l22) + delta
    Sigma <- sig2_save[i-1]*In + K
    W <- chol2inv(chol(Sigma))
    
    res <- Y2-X%*%beta_save[i-1,]
    
    sig2_save[i] <- 1/rgamma(1, N/2 + sig2a,
                             sig2b + 0.5*t(res)%*%W%*%res)
    
    Sigma <- sig2_save[i]*In + K
    W <- chol2inv(chol(Sigma))
    
    beta_save[i,] <- chol2inv(chol(t(X)%*%W%*%X))%*%t(X)%*%W%*%Y2
    
    tau21_star <- rnorm(1, tau21_save[i-1], tau21_sd)
    tau21_save[i] <- tau21_save[i-1]
    
    if (tau21_star > 0){
      K_star <- kernel(x2, tau21_star, tau22_save[i-1], l21, l22) + delta
      Sigma_star <- sig2_save[i]*In + K_star
      W_star <- chol2inv(chol(Sigma_star))
      
      acc_prob <- 
        -1/2*determinant(Sigma_star, logarithm = TRUE)$modulus[1] -
        1/2*t(res)%*%W_star%*%res + (tau21a-1)*log(tau21_star) -
        tau21b*tau21_star + 
        1/2*determinant(Sigma, logarithm = TRUE)$modulus[1] +
        1/2*t(res)%*%W%*%res - (tau21a-1)*log(tau21_save[i-1]) +
        tau21b*tau21_save[i-1]
      
      if (log(runif(1)) < acc_prob){
        tau21_save[i] <- tau21_star
        K <- K_star
        W <- W_star
        Sigma <- Sigma_star
      } 
    }
    
    tau22_star <- rnorm(1, tau22_save[i-1], tau22_sd)
    tau22_save[i] <- tau22_save[i-1]
    
    if (tau22_star > 0){
      K_star <- kernel(x2, tau21_save[i], tau22_star, l21, l22) + delta
      Sigma_star <- sig2_save[i]*In + K_star
      W_star <- chol2inv(chol(Sigma_star))
      
      acc_prob <- 
        -1/2*determinant(Sigma_star, logarithm = TRUE)$modulus[1] -
        1/2*t(res)%*%W_star%*%res + (tau22a-1)*log(tau22_star) -
        tau22b*tau22_star + 
        1/2*determinant(Sigma, logarithm = TRUE)$modulus[1] +
        1/2*t(res)%*%W%*%res - (tau22a-1)*log(tau22_save[i-1]) +
        tau22b*tau22_save[i-1]
      
      if (log(runif(1)) < acc_prob){
        tau22_save[i] <- tau22_star
        K <- K_star
        W <- W_star
        Sigma <- Sigma_star
      } 
    }
    
    pb$tick()
  }
  
  parm_names <- c("b0", "b1", "b2", "sig2", "tau21", "tau22")
  parm_samples <- cbind(beta_save, sig2_save, tau21_save, tau22_save)
  colnames(parm_samples) <- parm_names
  
  list(samples = parm_samples,
       acc_rates = c(sum(diff(tau21_save)!=0)/niter,
                     sum(diff(tau22_save)!=0)/niter))
}

gp.temp.cluster <- function(mcmc_comb){
  x <- mcmc_comb[["x"]]
  Y <- mcmc_comb[["Y"]]
  niter <- mcmc_comb[["niter"]]
  parm_inits <- mcmc_comb[["parm_inits"]]
  prior_parms <- mcmc_comb[["prior_parms"]]
  mh_parms <- mcmc_comb[["mh_parms"]]
  length_scales <- mcmc_comb[["length_scales"]]
  
  gp.temp(x, Y, niter, parm_inits, prior_parms,
          mh_parms, length_scales)
}

space.kern <- function(D, l2){
  exp(-1/(2*l2)*D)
}

space.D <- function(lat_long){
  D <- as.matrix(dist(lat_long, diag = TRUE, upper = TRUE))^2
}

time.kern <- function(D, l2){
  exp(-1/(2*l2)*D)
}

time.D <- function(tt){
  D <- as.matrix(dist(tt, diag = TRUE, upper = TRUE))^2
}

gau.pro.spat.temp <- function(data, niter, 
                              l2_space = 0.005, l2_time = 12,
                              prior_a = 3, prior_b = 5, var_init = 2){
  Y <- log(data[,3]+1)
  tt <- unique(data[,2])
  
  Ymean <- mean(Y)
  Ysd <- sd(Y)
  Y <- (Y-Ymean)/Ysd
  
  lat_long <- unique(data[,4:5])
  rownames(lat_long) <- NULL
  
  N <- length(tt)*nrow(lat_long)
  
  D_space <- space.D(lat_long)
  K_space <- space.kern(D_space, l2_space) + diag(10e-06, nrow(lat_long))
  D_time <- time.D(tt)
  K_time <- time.kern(D_time, l2_time) + diag(10e-06, length(tt))
  
  K_space_inv <- solve(K_space)
  K_time_inv <- solve(K_time)
  
  f_save <- matrix(0, niter, length(Y))
  sig2_save <- rep(0, niter)
  tau2_space_save <- rep(0, niter)
  tau2_time_save <- rep(0, niter)
  
  sig2_a <- prior_a
  sig2_b <- prior_b
  tau2_time_a <- prior_a
  tau2_time_b <- prior_b
  tau2_space_a <- prior_a
  tau2_space_b <- prior_b
  
  sig2_save[1] <- var_init
  tau2_space_save[1] <- var_init
  tau2_time_save[1] <- var_init
  
  for (i in 2:niter){
    K_space_time <- kronecker(tau2_space_save[i-1]*K_space,
                         tau2_time_save[i-1]*K_time)
    sig2I <- diag(sig2_save[i-1], N)
    f_Sigma <- K_space_time + sig2I
    
    f_Mu <- K_space_time%*%solve(f_Sigma, Y)
    f_Sigma <- K_space_time - K_space_time%*%solve(f_Sigma, K_space_time)
    
    f_save[i,] <- rmvnorm(1, f_Mu, f_Sigma)
    
    sig2_save[i] <- 1/rgamma(1, sig2_a + N/2, 
                             sig2_b + 0.5*t(Y-f_save[i,])%*%(Y-f_save[i,]))
    
    tau2_space_Sigma <- kronecker(K_space_inv, 1/tau2_time_save[i-1]*K_time_inv)
    
    tau2_space_save[i] <- 1/rgamma(1, tau2_space_a + N/2, 
                                tau2_space_b + 0.5*t(f_save[i,])%*%tau2_space_Sigma%*%f_save[i,])
    
    tau2_time_Sigma <- kronecker(1/tau2_space_save[i]*K_space_inv, K_time_inv)
    
    tau2_time_save[i] <- 1/rgamma(1, tau2_time_a + N/2, 
                                  tau2_time_b + 0.5*t(f_save[i,])%*%tau2_time_Sigma%*%f_save[i,])
  }
  
  cbind(f_save, sig2_save, tau2_space_save, tau2_time_save)
}
```

```{r}
parm_inits1 <- list(beta = c(0, 0, 0),
                    sig2 = 0.5, 
                    tau21 = 5, 
                    tau22 = 5)

parm_inits2 <- list(beta = c(10, -10, 0),
                    sig2 = 5,
                    tau21 = 1,
                    tau22 = 1)

parm_inits3 <- list(beta = c(0, 10, -10),
                    sig2 = 1,
                    tau21 = 10,
                    tau22 = 1)

prior_parms <- list(sig2a = 3, sig2b = 5, tau21a = 1.5, tau21b = 0.2,
                   tau22a = 1.5, tau22b = 0.2)

mh_parms <- list(tau21_sd = 0.15, tau22_sd = 15)

length_scales1 <- list(l21 = 365.25/52, l22 = 365.25/52)
length_scales2 <- list(l21 = 365.25/12, l22 = 365.25/52)
length_scales3 <- list(l21 = 365.25/52, l22 = 365.25/12)
length_scales4 <- list(l21 = 365.25/12, l22 = 365.25/12)
```

```{r}
load(file = "C://Users/david/Documents/R/Stat 695/Project/uber/trip_counts.RData")

Y <- trip_counts$n_trips
sdY <- sd(Y)
meanY <- mean(Y)
x <- 1:length(Y)
Y2 <- scale(Y)
x2 <- x-mean(x)
X <- cbind(1, x2, x2^2)
N <- length(Y)
In <- diag(N)
burn <- 1000
niter <- 10000

no_cores <- 3
cl <- makeCluster(no_cores)
registerDoParallel(cl)

mcmc_combs1 <- list(comb1 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits1,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales1),
                   comb2 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits2,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales1),
                   comb3 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits3,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales1))

mcmc_combs2 <- list(comb1 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits1,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales1),
                    comb2 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits1,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales2),
                    comb3 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits1,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales3),
                    comb4 = list(x = x, Y = Y, niter = niter,
                                parm_inits = parm_inits1,
                                prior_parms = prior_parms,
                                mh_parms = mh_parms,
                                length_scales = length_scales4))

clusterExport(cl, list("gp.temp", "gp.temp.cluster", "exp.kernel", 
                       "period.kernel", "kernel", "mcmc_combs1",
                       "mcmc_combs2"))
clusterEvalQ(cl, library("progress"))

cluster_out1 <- parLapply(cl, mcmc_combs1, gp.temp.cluster)
cluster_out2 <- parLapply(cl, mcmc_combs2, gp.temp.cluster)
```

```{r}
samps11 <- cluster_out1$comb1$samples
samps12 <- cluster_out1$comb2$samples
samps13 <- cluster_out1$comb3$samples
all_samps1 <- rbind(samps11[burn:niter,], 
                    samps12[burn:niter,], 
                    samps13[burn:niter,])

samps21 <- cluster_out2$comb1$samples
samps22 <- cluster_out2$comb2$samples
samps23 <- cluster_out2$comb3$samples
samps24 <- cluster_out2$comb4$samples
all_samps2 <- rbind(samps21[burn:niter,], 
                    samps22[burn:niter,], 
                    samps23[burn:niter,],
                    samps24[burn:niter,])

mcmc_samps11 <- as.mcmc(samps11)
mcmc_samps12 <- as.mcmc(samps12)
mcmc_samps13 <- as.mcmc(samps13)

mcmc_samps_list <- mcmc.list(mcmc_samps11, 
                             mcmc_samps12, 
                             mcmc_samps13)

gelman_diag <- gelman.diag(mcmc_samps_list)

kable(gelman_diag$psrf, format = "latex", digits = 4)

ess <- effectiveSize(mcmc_samps_list)

kable(ess, format = "latex", digits = 4)

pdf(file = "~/traceplots.pdf", width = 8, height = 10)
par(mfrow = c(6, 1), mar = c(5, 5, 1, 1))
traceplot(as.mcmc(all_samps1))
par(mfrow = c(1, 1))
dev.off()

post_mean1 <- colMeans(samps21[burn:niter,])
post_mean2 <- colMeans(samps22[burn:niter,])
post_mean3 <- colMeans(samps23[burn:niter,])
post_mean4 <- colMeans(samps24[burn:niter,])
post_means <- cbind(post_mean1, post_mean2,
                    post_mean3, post_mean4)

colnames(post_means) <- c("l21=7, l22=7",
                          "l21=30, l22=7",
                          "l21=7, l22=30",
                          "l21=30, l22=30")

kable(post_means, format = "latex", digits = 6)

Xb_post <- matrix(0, nrow(all_samps1), length(Y))
f1_post <- matrix(0, nrow(all_samps1), length(Y))
f2_post <- matrix(0, nrow(all_samps1), length(Y))
Y_pred <- matrix(0, nrow(all_samps1), length(Y))
max_gap_Y <- rep(0, nrow(all_samps1))
max_gap_Y_pred <- rep(0, nrow(all_samps1))

for (i in 1:nrow(all_samps1)){
  b <- cbind(all_samps1[i,1:3])
  Xb_post[i,] <- X%*%b
  K1 <- exp.kernel(x2, all_samps1[i,5], 7)
  K2 <- period.kernel(x2, all_samps1[i,6], 7)
  Sigma <- K1+K2+all_samps1[i,4]*In
  Wres <- chol2inv(chol(Sigma))%*%(Y2-Xb_post[i,])
  f1_post[i,] <- K1%*%Wres
  f2_post[i,] <- K2%*%Wres
  Mu_new <- Xb_post[i,] - f1_post[i,] - f2_post[i,]
  res_new <- Y2-Mu_new
  sig2_new <- 1/rgamma(1, prior_parms[["sig2a"]] + N/2,
                       prior_parms[["sig2b"]] + 
                         0.5*t(res_new)%*%(res_new))
  Y_pred[i,] <- rmvnorm(1, Xb_post[i,] + 
                      f1_post[i,] + 
                      f2_post[i,], sig2_new*In)
  max_gap_Y[i] <- max(Y2-Mu_new)
  max_gap_Y_pred[i] <- max(Y_pred[i,]-Mu_new)
}

pdf(file = "~/post_pred_check.pdf",
    width = 5,
    height = 5)
par(mar = c(5, 5, 4, 1))
plot(max_gap_Y_pred, max_gap_Y, 
     main = "Maximum Gap Posterior Predictive Check",
     xlab = expression(MG~"("~Y[pred]~","~theta~")"),
     ylab = expression(MG~"("~Y~","~theta~")"))
abline(a=0, b=1, col = 'red', lwd = 2)
dev.off()

post_mean_pred <- colMeans(Xb_post + f1_post + f2_post)*sdY + meanY
Xb_pred <- colMeans(Xb_post)*sdY + meanY
f1_pred <- colMeans(f1_post)*sdY
f2_pred <- colMeans(f2_post)*sdY

pdf(file = "~/predictions.pdf",
    height = 5,
    width = 7)
plot(trip_counts$date, Y, type = 'l',
     main = "Observed Counts with Posterior Mean Line",
     ylab = "Daily Count",
     xlab = "Date")
lines(trip_counts$date, post_mean_pred, col = 'red')
dev.off()

pdf(file = "~/trends.pdf", width = 8,
    height = 10)
par(mfrow = c(3, 1), mar = c(5, 5, 1, 1))
plot(trip_counts$date, Xb_pred, type = 'l',
     main = "Increasing Trend",
     ylab = "Counts",
     xlab = "Date")
plot(trip_counts$date, f1_pred, type = "l",
     main = "Yearly Trend",
     ylab = "Change from Baseline",
     xlab = "Date")
plot(trip_counts$date, f2_pred, type = "l",
     main = "Weekly Trend",
     ylab = "Change from Baseline",
     xlab = "Date")
par(mfrow = c(1, 1))
dev.off()

pdf(file = "~/weekly_trend.pdf", height = 5,
    width = 7)
plot(trip_counts$date[1:7], f2_pred[1:7], type = "l",
     main = "Weekly Trend",
     ylab = "Change from Baseline",
     xlab = "Date")
dev.off()
```

```{r}
load(file = "C://Users/david/Documents/R/Stat 695/Project/uber/trip_data.RData")

Y <- trip_data[,3]
Y2 <- log(trip_data[,3]+1)
tt <- unique(trip_data[,2])

Y2mean <- mean(Y2)
Y2sd <- sd(Y2)
Y2 <- (Y2-Y2mean)/Y2sd

lat_long <- unique(trip_data[,4:5])
rownames(lat_long) <- NULL

N <- length(tt)*nrow(lat_long)
In <- diag(N)

burn <- 1000
niter <- 10000

mcmc_combs1 <- list(data = trip_data, niter = niter,
                    l2_space = 0.005, l2_time = 12, prior_a = 3,
                    prior_b = 5, var_init = 2)
mcmc_combs2 <- list(data = trip_data, niter = niter,
                    l2_space = 0.005, l2_time = 12, prior_a = 3,
                    prior_b = 5, var_init = 10)
mcmc_combs3 <- list(data = trip_data, niter = niter,
                    l2_space = 0.005, l2_time = 12, prior_a = 3,
                    prior_b = 5, var_init = 100)

mcmc_combs <- list(comb1 = mcmc_combs1,
                   comb2 = mcmc_combs2,
                   comb3 = mcmc_combs3)

no_cores <- 3
cl <- makeCluster(no_cores)
registerDoParallel(cl)

clusterExport(cl, list("gau.pro.spat.temp", 
                       "space.kern", "space.D", "time.kern",
                       "time.D", "mcmc_combs"))
clusterEvalQ(cl, library(mvtnorm))

spat_temp_out <- parLapply(cl, mcmc_combs, function(x){
  data <- x[["data"]]
  niter <- x[["niter"]]
  l2_space <- x[["l2_space"]]
  l2_time <- x[["l2_time"]]
  prior_a <- x[["prior_a"]]
  prior_b <- x[["prior_b"]]
  var_init <- x[["var_init"]]

  gau.pro.spat.temp(data, niter, l2_space, l2_time,
                    prior_a, prior_b, var_init)
})
```

```{r}
st_samps1 <- spat_temp_out$comb1
st_samps2 <- spat_temp_out$comb2
st_samps3 <- spat_temp_out$comb3
colnames(st_samps1) <- c(rep("", N), "sig2", "tau2_space", "tau2_time")
colnames(st_samps2) <- c(rep("", N), "sig2", "tau2_space", "tau2_time")
colnames(st_samps3) <- c(rep("", N), "sig2", "tau2_space", "tau2_time")

all_samps <- rbind(st_samps1[burn:niter,],
                   st_samps2[burn:niter,],
                   st_samps3[burn:niter,])

mcmc_samps_list <- mcmc.list(as.mcmc(st_samps1[,(N+1):(N+3)]), 
                             as.mcmc(st_samps2[,(N+1):(N+3)]), 
                             as.mcmc(st_samps3[,(N+1):(N+3)]))

gelman_diag <- gelman.diag(mcmc_samps_list)

kable(gelman_diag$psrf, format = "latex", digits = 4)

ess <- effectiveSize(mcmc_samps_list)

kable(t(ess), format = "latex", digits = 4)

pdf(file = "~/st_traceplots.pdf", width = 8, height = 10)
par(mfrow = c(3, 1), mar = c(5, 5, 1, 1))
traceplot(as.mcmc(all_samps[,(N+1):(N+3)]))
par(mfrow = c(1, 1))
dev.off()

post_pred <- matrix(0, nrow(all_samps), N)
post_Mu <- exp(colMeans(all_samps[,1:N]*Y2sd + Y2mean))

for (i in 1:nrow(all_samps)){
  curf <- all_samps[i,1:N]
  post_pred[i,] <- t(rmvnorm(1, curf, all_samps[i,N+1]*In))
}

post_Y_var <- rep(0, nrow(all_samps))
post_Y_pred_var <- rep(0, nrow(all_samps))

for (i in 1:nrow(all_samps)){
  post_Y_var[i] <- mean((Y2-all_samps[i,1:N])^2)
  post_Y_pred_var[i] <- mean((post_pred[i,] - all_samps[i,1:N])^2)
}

pdf(file = "~/st_post_pred_check.pdf",
    width = 5,
    height = 5)
par(mar = c(5, 5, 4, 1))
plot(post_Y_pred_var, post_Y_var, 
     main = "Posterior Predictive Check of Variability",
     xlab = expression(Var~"("~Y[pred]~","~theta~")"),
     ylab = expression(Var~"("~Y~","~theta~")"),
     ylim = c(0.02, 0.07))
abline(a=0, b=1, col = 'red', lwd = 2)
dev.off()

trip_data$Predictions <- post_Mu

pdf(file = "~/st_predictions.pdf",
    height = 6,
    width = 8)
xyplot(log(Count) + log(Predictions) ~ Hour | Location, data = trip_data,
       main = "True Log Counts with Log Predictions",
       ylab = "Log Counts", type = 'l')
dev.off()
```

```{r}
pdf(file = "~/daily_trips.pdf",
    height = 5,
    width = 7)
plot(trip_counts$date, trip_counts$n_trips,
     main = "Daily Trips (Sept 2014 - Aug 2015)",
     xlab = "Date", ylab = "Count", type = 'l')
dev.off()

pdf(file = "~/st_data.pdf",
    height = 6,
    width = 8)
xyplot(log(Count) ~ Hour | Location, data = trip_data,
       main = "Log Hourly Trips ",
       ylab = "Log Counts", type = 'l')
dev.off()
```

```{r}
# make graph of original dataset
all_edges <- readRDS("all_edges.Rda")
n<- dim(all_edges)[1]
e1<-matrix(NA,nrow=n,ncol=3)
for(i in 1:n) {
  e1[i,] = c(all_edges[[i,1]],all_edges[[i,2]],all_edges[[i,3]]) # from, to, weight
}
g<-graph_from_edgelist(e1[,1:2], directed=FALSE)
pdf(file = "~/uber_graph.pdf", height = 5, width = 5)
plot(g, layout=layout.circle, main=paste("Uber as a graph, with ", length(V(g)), "vertices,", length(E(g)), "edges."))
dev.off()
```

```{r}
topk_edges <- readRDS("topk.Rda")
n<- dim(topk_edges)[1]
edgematrix<-matrix(NA,nrow=n,ncol=3)
for(i in 1:n) {
  edgematrix[i,] = c(topk_edges[[i,1]],topk_edges[[i,2]],topk_edges[[i,3]])
}
g<-graph_from_edgelist(edgematrix[,1:2], directed=FALSE)
pdf(file = "~/uber_small_graph.pdf", height = 5, width = 5)
plot(g, layout=layout.circle, main=paste("Uber top-100 subgraph, Vertices:", length(V(g)), "Edges:", length(E(g))))
dev.off()
```

```{r}
highfare_matrix = edgematrix[as.numeric(edgematrix[,3]) > 60,]
highfare_weights = round(as.numeric(highfare_matrix[,3]))
g2<-graph_from_edgelist(highfare_matrix[,1:2], directed=FALSE)
pdf(file = "~/lucrative_subraph.pdf", width = 5, height = 5)
plot(g2,edge.label= highfare_weights, layout=layout.circle)
dev.off()
```

```{r}
for(fares in seq(60,45,-5)) {
  highfare_matrix = edgematrix[as.numeric(edgematrix[,3]) > fares,]
  g2<-graph_from_edgelist(highfare_matrix[,1:2], directed=FALSE)
  lengths = c()

  for (v in V(g2)$name) {
    res = all_simple_paths(g2,v)
   lengths = c(lengths, max(sapply(1:length(res), function(j) { length(res[[j]]) })))
  }
  cat(sprintf("Fare: $%.0f, Longest path: %.0f, Vertices:%.0f Edges %.0f\n", fares, max(lengths), length(V(g2)),length(E(g2))))
}

# visualize the graph with simple path of length 8
highfare_matrix = edgematrix[as.numeric(edgematrix[,3]) > 46,]
highfare_weights = round(as.numeric(highfare_matrix[,3]))
g3<-graph_from_edgelist(highfare_matrix[,1:2], directed=FALSE)
paths_of_length_8 = c()
found=FALSE
for (src in V(g3)$name) {
    res = all_simple_paths(g3,src)
    for(i in 1:length(res)) {
      l = length(res[[i]])
      last = res[[i]][l]$name
      d = distances(g3,v=last,to=src)
      if (l == 8 & d[1] == 1) {
          paths_of_length_8 = c(paths_of_length_8, res[[i]])
          #print(res[[i]])
          found = TRUE
          break
      }
    }
    if(found) break
}
pdf(file = "~/lucrative_subgraph2.pdf")
plot(g3, mark.groups=names(paths_of_length_8[1:8]), mark.col="red")
dev.off()
```

```{}
getidx = function(src,dest) {
  #cat(paste(src,",",dest, "\n"))
  srcidx = which(topk_edges == src, arr.ind=TRUE)
  destidx = which(topk_edges == dest, arr.ind=TRUE)
 
  r = intersect(srcidx[,1], destidx[,1])[1]
  #print(srcidx)
  #print(destidx)
  #print(r)
  return(r)
}

get_fare_dist = function(src,dest) {
   r = getidx(src,dest)
   return(topk_edges[[r,4]])
}

get_median_fare=function(src,dest) {
  r = getidx(src,dest)
  if (topk_edges[[r,1]] == src & topk_edges[[r,2]] == dest) {
     return(topk_edges[[r,3]])  
  } else if (topk_edges[[r,2]] == src & topk_edges[[r,1]] == dest) {
    return(topk_edges[[r,3]])
  } else return(-1)
}


vlist = c()
for(i in 1:7) {
  vlist = c(vlist, names(paths_of_length_8[i]), names(paths_of_length_8[i+1]))
}
vlist = c(vlist, names(paths_of_length_8[8]), names(paths_of_length_8[1]))
edge_wt = numeric(8)
for(i in 0:7) {
  f = 2*i + 1
  t = f+1
  sf = vlist[f]
  dt = vlist[t]
  edge_wt[i+1] = get_median_fare(sf,dt)
}

pdf(file = "~/optimal_graph.pdf", height = 6, width = 6)
plot(make_undirected_graph(vlist),edge.color="red", layout=layout.circle, edge.label=round(edge_wt))
dev.off()
```

```{r}
stats_df = data.frame()
ckt_dist = numeric(8)
for(i in 0:7) {
  f = 2*i + 1
  t = f+1
  sf = vlist[f]
  dt = vlist[t]
  dist = get_fare_dist(sf,dt)
  ckt_dist[(i+1)] = getidx(sf,dt)
  stats_df[(i+1),1:2] = c(sf,dt)
  stats_df[(i+1),3:6] = round(c(mean(dist), median(dist), sd(dist), var(dist)),2)
}
colnames(stats_df) <- c("Src", "Dest", "Mean", "Median", "Sigma", "Var")
kable(stats_df, format = "latex", digits = 4)
```

```{r}
#obtain n samples from the circuit just once
n = 1000
get_circuit_sample <- function() {
  return(sum(sapply(1:8, function(i) { 
    r = ckt_dist[i]
    dist = topk_edges[[r,4]]  
    sample(dist,1) 
  })))
}

y_i = sapply(1:n, function(i){get_circuit_sample()})

pdf(file = "~/edge_dists.pdf", width = 8, height = 6)
par(mfrow=c(2,4))
for(i in 1:8) {
  r = ckt_dist[i]
  dist = topk_edges[[r,4]]  
  hist(dist,breaks=20, main=paste("Edge ", vlist[2*(i-1)+1], "->", vlist[2*i]))
}
dev.off()
par(mfrow = c(1, 1))
```

```{r}
n = 50
edge_fares = sapply(1:8, function(i) { 
    r = ckt_dist[i]
    dist = topk_edges[[r,4]]  
    mean(dist[1:n]) 
  })

# data
sigma_y = n*sum(edge_fares)
sigmasq = 392 # 6sigma = 42, sigma^2 = 49, 8*sigma^2 = 392

# prior
mu0 = 400 #$50 per edge times 8
tau0sq = 392 

# posterior
denom = (1/tau0sq) + (n/sigmasq)
mu = (mu0/tau0sq + sigma_y/sigmasq)/denom
sigmasq_post = 1/denom

#plotting vars
x = seq(mu0-3*sqrt(tau0sq),mu0+3*sqrt(tau0sq),.1)
y = dnorm(x,mean=mu,sd=sqrt(sigmasq_post))
yp = dnorm(x,mean=mu0,sd=sqrt(tau0sq))

# Gaussian prior
pdf(file = "~/prior_post.pdf", height = 5, width = 5)
plot(x,y, main=paste("Posterior Mean:",round(mu,2)), col="blue", "l")
lines(x,yp,col="red")
abline(v=mu0, col="red")
dev.off()
```

```{r}

scode <- "
data {
  int<lower=0> N;
  vector[N] y;
  vector[N] x1;
  vector[N] x2;
  vector[N] x3;
  vector[N] x4;
  vector[N] x5;
  vector[N] x6;
  vector[N] x7;
  vector[N] x8;
}

parameters {
  real mu1;
  real mu2;
  real mu3;
  real mu4;
  real mu5;
  real mu6;
  real mu7;
  real mu8;
  real mu;
  real<lower=0> phi; 
  real<lower=0> sigma;
}

model {
  y ~ normal(mu*8, sqrt(8)*sigma);
  x1 ~ normal(mu1, sigma);
  x2 ~ normal(mu2, sigma);
  x3 ~ normal(mu3, sigma);
  x4 ~ normal(mu4, sigma);
  x5 ~ normal(mu5, sigma);
  x6 ~ normal(mu6, sigma);
  x7 ~ normal(mu7, sigma);
  x8 ~ normal(mu8, sigma);
  mu1 ~ normal(mu, phi);
  mu2 ~normal(mu,phi);
  mu3 ~normal(mu,phi);
  mu4 ~ normal(mu, phi);
  mu5 ~normal(mu,phi);
  mu6 ~normal(mu,phi);
  mu7 ~ normal(mu, phi);
  mu8 ~normal(mu,phi);
}
"
find_edge_dist = function(i,N) {
  return(sample(topk_edges[[ckt_dist[i],4]],N,FALSE))
}

N=50
x = matrix(0,8,N)
y = numeric(50)
for( i in 1:8) {
  x[i,] = find_edge_dist(i,N)
  y = y + x[i,]
}
pdf(file = "~/fare_distribution.pdf", height = 5, width = 6)
hist(y, main="Fare distribution of Optimal Daily Circuit")
dev.off()
```

```{r}
data = list(N=N,x1=x[1,],x2=x[2,],x3=x[3,],x4=x[4,],x5=x[5,],x6=x[6,],x7=x[7,],x8=x[8,],y=y)

rstan_options(auto_write = FALSE)
options(mc.cores = parallel::detectCores())
fit <- stan(model_code = scode, data = data, iter=500, warmup=50,chains=1)
```

```{r}
s<-summary(fit, probs = c(0.5))
optimal_fare<-8*s$summary[9]
pdf(file = "~/stan_post.pdf", width = 5, height = 5)
suppressMessages(plot(fit, pars=c("mu","phi","mu1","mu2","mu3","mu4","mu5","mu6","mu7","mu8")))
dev.off()
```

```{r}
pdf(file = "~/mu_post.pdf", width = 6, height = 5)
cat(sprintf("Mean Fare from Optimal Daily Circuit $%.2f\n", optimal_fare))
traceplot(fit,pars="mu")
dev.off()
```

```{r}
N=50
x = matrix(0,8,N)
ry = numeric(50)
set.seed(12343)
random_paths = sample(1:812,8)
find_path_dist = function(i,N) {
  return(sample(all_edges[[i,4]],N,FALSE))
}
for( i in 1:8) {
  x[i,] = find_path_dist(random_paths[i],N)
  ry = ry + x[i,]
}

data = list(N=N,x1=x[1,],x2=x[2,],x3=x[3,],x4=x[4,],x5=x[5,],x6=x[6,],x7=x[7,],x8=x[8,],y=ry)

rstan_options(auto_write = FALSE)
options(mc.cores = parallel::detectCores())
rfit <- stan(model_code = scode, data = data, iter=500, warmup=50,chains=1)
```

```{r}
rs<-summary(rfit, probs = c(0.5))
random_fare<-8*rs$summary[9]
daily_loss<- optimal_fare - random_fare

pdf(file = "~/random_post.pdf", height = 5, width = 5)
suppressMessages(plot(rfit, pars=c("mu","phi","mu1","mu2","mu3","mu4","mu5","mu6","mu7","mu8")))
dev.off()
```

```{r}
pdf(file = "~/random_post2.pdf")
cat(sprintf("Mean Fare from Random Daily Circuit $%.2f\n", random_fare))
cat(sprintf("|Optimal-Random| Median Loss: $%.2f\n", daily_loss))
traceplot(rfit,pars="mu")
dev.off()
```

```{r}
n<-14 # 2 weeks
options(digits=4)
c1<- sample(y,n)
c2<- sample(ry,n)

outersect <- function(x, y) {
  sort(c(x[!x%in%y],
         y[!y%in%x]))
}

 ".combinadic" <- function(n, r, i) {
     
     if(i < 1 | i > choose(n,r)) stop("'i' must be 0 < i <= n!/(n-r)!")
     
     largestV <- function(n, r, i) {
         v <- n                                  # Adjusted for one-based indexing
         while(choose(v,r) >= i) v <- v-1        # Adjusted for one-based indexing
         return(v)
     }
     
     res <- rep(NA,r)
     for(j in 1:r) {
         res[j] <- largestV(n,r,i)
         i <- i-choose(res[j],r)
         n <- res[j]
         r <- r-1
     }
     res <- res + 1
     return(res)
}
n=14
r<-(n/2)
len <- choose(n,r)
t <- numeric(len)
for(i in 1:len) {
  assignment<-.combinadic(n,r,i)
  y_obs <- c1
  y_obs[assignment] <- c2[assignment]
  not_assigned <- outersect(1:n, assignment)
  # want Ybar(1) - Ybar(0) on the observed
  diff <- mean(y_obs[assignment]) - mean(y_obs[not_assigned])
  t[i] <- diff
}

m<- round(max(abs(min(t)), abs(max(t))))
theta <- seq(-m,m,1)
nt <- length(t)
pvalues<-c()
for(mytheta in theta) {
  pval<- length(t[t < mytheta])/nt
  pvalues<-c(pvalues, pval)
}

pdf(file = "~/post_compare.pdf", width = 8, height = 5)
par(mfrow=c(1,2))
hist(t, main="Difference b/w wages of 2 ckts")
plot(theta,pvalues, main="p-value function", 'l')
abline(h=0.05,col='red')
abline(h=0.95,col='red')
dev.off()
```
