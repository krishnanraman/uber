---
title: "uber analysis"
author: "Krishnan Raman"
date: "10/6/2020"
output: pdf_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library("dplyr")
library(tidyverse)
library(lattice)

# CHANGE THIS TO LOCAL DRIVE WHERE uber_nyc_data.csv is located
# set nrows to 40 million
setwd("~/Desktop/695/uber-tlc-foil-response/uber-trip-data/")
df<-read.csv("uber_nyc_data.csv", nrows=1000*1000*40)

# convert factor vars to formatted numbers
df$distance = as.double(as.character(df$trip_distance))
df$duration = as.double(as.difftime(as.character(df$trip_duration), format = "%H:%M:%S", units = "mins"))

# find 1% & 99% quantiles, eliminate anything beyond
# this helps with cancelled trips, overly long trips & other weird outlier cases
durq = quantile(df$duration,c(0.01, 0.99), names=F, na.rm=T)
disq = quantile(df$distance,c(0.01, 0.99), names=F, na.rm=T)

df2 = df[df$duration > durq[1] & df$duration < durq[2] & df$distance > disq[1] & df$distance < disq[2],]
df2 = select(df2,2:4, 7:8)

# remove NAs & prev dataframes
final = df2[complete.cases(df2), ]
rm(df,df2)
```

compute fare based on linear combination of time and distance

```{r}

base_fare = 2.55
per_minute = 0.35
per_mile = 1.75
min_fare = 8
final$fare <- mapply(function(dis,dur) {
  max(min_fare, base_fare + per_minute*dur + per_mile*dis)
}, final$distance, final$duration)
# distance distribution, duration distribution
hist(final$distance)
hist(final$duration)
hist(final$fare)

# get summary stats
summary(final)
```
log transform for positive variates
```{r}
final$logdist = log(1.0+final$distance)
final$logdur = log(1.0 + final$duration)
final$logfare = log(final$fare)
```

gamma priors
```{r}
bestgammafit = function(x,title) {
dist_scale = var(x)/mean(x)
dist_shape = mean(x)/dist_scale
plot(density(x), main=title)
px=seq(0,5,0.05)
py=dgamma(px,scale=dist_scale, shape=dist_shape)
lines(px,py, col='red')
}

bestgammafit(final$logdist, "log distance")
bestgammafit(final$logdur, "log duration")
bestgammafit(final$logfare, "log fare")
```
Try exp ( Gamma(1)) & Pareto fits as well.
compute posterior from prior and likelihood
a-b-c-... circuit for highest fare, least distance

```{r}
# Read in first 1 million rows of data set

uber_orig <- read.csv("C://Users/david/Desktop/uber.csv", nrows = 1000*1000, stringsAsFactors = FALSE)
uber <- uber_orig

# Create a new variable with just the hour of pickup time

uber$origin_hour <- uber$pickup_datetime %>% str_split (" ") %>% lapply(function(x) x[2]) %>% unlist() %>% 
  substr(1,2) %>% as.numeric()

# Create another variable with minutes of trip

uber$trip_minutes <-  uber$trip_duration %>% str_split(":") %>% 
  lapply(function(x) 60*as.numeric(x[1])+as.numeric(x[2]) + round(as.numeric(x[3])/60)) %>% unlist()

# Create new variable with just the day

uber$trip_day <- as.Date(uber$pickup_datetime)

# Filter out some trips with missing data or excessive trip times
# Only selecting the first two weeks

uber_2weeks <- uber %>% filter(!(trip_minutes <= 0 | is.na(trip_minutes) == TRUE | 
                            trip_minutes > 100) & trip_day >= "2014-09-01" & trip_day <= "2014-09-15")

# Names of stations 

station_names <- unique(uber$origin_taz)

# Get the number of cars at each location at each hour of the day

loc_times <- uber_2weeks %>% group_by(origin_taz, origin_hour) %>% 
  summarise(num_cars = n()) %>% as.data.frame()

# Reformat into a matrix with hour of day as rows and location as columns

lt_mat <- matrix(0, 24, length(station_names)-1)

for (i in 1:(ncol(lt_mat))){
  lt_mat[,i] <- loc_times %>% filter(origin_taz == station_names[i]) %>% 
    select(num_cars) %>% `$`(num_cars)
}

# Plot the number of cars by hour at each location

xyplot(num_cars ~ origin_hour | origin_taz, data = loc_times)

# 2A is a very different location so plot just the other locations

loc_times %>% filter(origin_taz != "2A") %>% xyplot(num_cars ~ origin_hour | origin_taz, data = .)
```


